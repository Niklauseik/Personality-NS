import os
import re
import pandas as pd
from collections import Counter, defaultdict

# ========= æ•°æ®é›†é…ç½®ï¼ˆä¿æŒä½ çš„åŸæ ·ï¼‰ =========
datasets = [
    {"name":"imdb_sentiment","file":"imdb_sentiment_results.csv",
     "label_map":{"0":"negative","1":"positive"},
     "allowed_labels":None,"label_col":"label","pred_col":"prediction",
     "base_path":"results/sentiment/imdb"},
    {"name":"mental_sentiment","file":"mental_sentiment_results.csv",
     "label_map":None,"allowed_labels":["normal","depression"],
     "label_col":"label","pred_col":"prediction",
     "base_path":"results/sentiment/mental"},
    {"name":"news_sentiment","file":"news_sentiment_results.csv",
     "label_map":{"0":"bearish","1":"bullish","2":"neutral"},
     "allowed_labels":None,"label_col":"label","pred_col":"prediction",
     "base_path":"results/sentiment/news"},
    {"name":"fiqasa_sentiment","file":"fiqasa_fiqasa_sentiment_results.csv".replace("_fiqasa",""),
     "label_map":None,"allowed_labels":["negative","positive","neutral"],
     "label_col":"answer","pred_col":"prediction",
     "base_path":"results/sentiment/fiqasa"},
    {"name":"imdb_sklearn","file":"imdb_sklearn_sentiment_results.csv",
     "label_map":{"0":"negative","1":"positive"},
     "allowed_labels":None,"label_col":"label","pred_col":"prediction",
     "base_path":"results/sentiment/imdb_sklearn"},
    {"name":"sst2","file":"sst2_sentiment_results.csv",
     "label_map":{"0":"negative","1":"positive"},
     "allowed_labels":None,"label_col":"label","pred_col":"prediction",
     "base_path":"results/sentiment/sst2"},
]

models = {"base":"åŸå§‹åŸºåº§æ¨¡å‹","n":"Næ€§æ ¼æ¨¡å‹","s":"Sæ€§æ ¼æ¨¡å‹"}

# ====== ä»…å¿½ç•¥å¤§å°å†™ + å°¾éƒ¨å¥å·ï¼ˆè‹±æ–‡. / ä¸­æ–‡ã€‚ / çœç•¥å·â€¦ï¼‰ï¼Œä¸ç§»é™¤å…¶å®ƒæ ‡ç‚¹ ======
TAILING_DOTS_PATTERN = re.compile(r'[\.ã€‚â€¦]+$')  # åªæ¸…ç†å°¾éƒ¨å¥å·

def norm_label(s: str) -> str:
    if not isinstance(s, str):
        return ""
    s = s.strip()
    s = TAILING_DOTS_PATTERN.sub("", s)  # ä»…å»æ‰â€œæœ«å°¾â€çš„å¥å·
    return s.lower()

dist_all = defaultdict(lambda: defaultdict(lambda: {"true":0, "base":0, "f":0, "t":0}))

for ds in datasets:
    print(f"ğŸ” å¤„ç†æ•°æ®é›†ï¼š{ds['name']}")
    # åŸºç¡€å…è®¸é›†åˆï¼ˆæ ‡å‡†åŒ–åï¼‰
    allowed = set() if ds["allowed_labels"] is None else {norm_label(x) for x in ds["allowed_labels"]}
    true_done = False

    for mkey, mfolder in models.items():
        path = os.path.join(ds["base_path"], mfolder, ds["file"])
        if not os.path.exists(path):
            print(f"  âš ï¸ ç¼ºå°‘æ–‡ä»¶ï¼š{path}")
            continue

        df = pd.read_csv(path, dtype=str).fillna("")
        original_df = df.copy()

        # çœŸå®æ ‡ç­¾æ˜ å°„ï¼ˆå¦‚æœ‰ï¼‰
        if ds["label_map"] is not None:
            df[ds["label_col"]] = df[ds["label_col"]].astype(str).map(ds["label_map"])

        # ä»…åšï¼šå¤§å°å†™å¿½ç•¥ + å»é™¤æœ«å°¾å¥å·
        df[ds["label_col"]] = df[ds["label_col"]].map(norm_label)
        df["cleaned_pred"]  = df[ds["pred_col"]].map(norm_label)

        # è‹¥æ²¡æä¾› allowedï¼Œåˆ™ç”¨æ˜ å°„å€¼æˆ–çœŸå®æ ‡ç­¾é›†åˆï¼ˆæ ‡å‡†åŒ–ï¼‰
        if not allowed:
            if ds["label_map"] is not None:
                allowed = {norm_label(v) for v in ds["label_map"].values()}
            else:
                allowed = set(df[ds["label_col"]].unique())

        # ç»Ÿè®¡çœŸå®åˆ†å¸ƒ
        if not true_done:
            for lbl, cnt in Counter(df[ds["label_col"]]).items():
                if lbl in allowed:
                    dist_all[ds["name"]][lbl]["true"] = cnt
            true_done = True

        # é¢„æµ‹åˆ†å¸ƒ â€”â€” ä¸¥æ ¼ç­‰å€¼åŒ¹é…åˆ° allowed é‡Œï¼ˆåªåšå¤§å°å†™&å°¾å¥å·æ”¾å®½ï¼‰
        for lbl in allowed:
            match_count = (df["cleaned_pred"] == lbl).sum()
            dist_all[ds["name"]][lbl][mkey] = match_count

        # ===== åˆè§„åˆ¤æ–­ï¼šé™¤äº† allowedï¼Œè¿˜é¢å¤–å…è®¸ mixed / neutralï¼ˆå¯å¸¦å°¾å¥å·ï¼Œå·²ç”± norm å¤„ç†ï¼‰=====
        extra_ok = {"mixed", "neutral"}
        is_valid = df["cleaned_pred"].isin(allowed.union(extra_ok))

        # ä¿å­˜â€œå®Œå…¨ä¸ç¬¦åˆâ€çš„ prediction
        invalid_df = original_df[~is_valid].copy()
        invalid_path = os.path.join(ds["base_path"], mfolder, ds["file"].replace(".csv", ".invalid.csv"))
        if not invalid_df.empty:
            invalid_df.to_csv(invalid_path, index=False)
            print(f"  ğŸš« éæ³• prediction æ¡ç›®å·²ä¿å­˜è‡³ï¼š{invalid_path}")
        else:
            print(f"  âœ… æ‰€æœ‰ prediction éƒ½æ˜¯è§„èŒƒæ ‡ç­¾ï¼ˆå« mixed/neutralï¼‰")
